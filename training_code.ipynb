{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505c172d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saileshkumar\\AppData\\Local\\anaconda3\\envs\\restaurant\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.748059280169372\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.47      0.59       256\n",
      "           2       0.69      0.39      0.50       251\n",
      "           3       0.64      0.46      0.54       589\n",
      "           4       0.63      0.40      0.48      1597\n",
      "           5       0.78      0.95      0.86      4392\n",
      "\n",
      "    accuracy                           0.75      7085\n",
      "   macro avg       0.70      0.54      0.59      7085\n",
      "weighted avg       0.73      0.75      0.72      7085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "  \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    " \n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "  \n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_dataset.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "with open('xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_classifier, f)\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "test_review = \"adding some review from data base for testing\"\n",
    "preprocessed_review = preprocess_text(test_review)\n",
    "test_review_tfidf = tfidf_vectorizer.transform([preprocessed_review])\n",
    "predicted_rating = xgb_classifier.predict(test_review_tfidf)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe7c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17692)\t0.3543563017581065\n",
      "  (0, 9139)\t0.35846817606428555\n",
      "  (0, 18806)\t0.5454667872787481\n",
      "  (0, 21969)\t0.6696253894001206\n",
      "  (1, 10432)\t0.24765951463373811\n",
      "  (1, 19953)\t0.08495912508170472\n",
      "  (1, 3374)\t0.19501181619446237\n",
      "  (1, 2426)\t0.0987614389409748\n",
      "  (1, 1760)\t0.08698629841794865\n",
      "  (1, 10650)\t0.30734241785048166\n",
      "  (1, 16015)\t0.1728371642961198\n",
      "  (1, 21930)\t0.07139307438174394\n",
      "  (1, 6346)\t0.13236460456852184\n",
      "  (1, 20215)\t0.05648942238784103\n",
      "  (1, 13476)\t0.15329309258901375\n",
      "  (1, 9561)\t0.08310082670587154\n",
      "  (1, 15738)\t0.27286144592783873\n",
      "  (1, 11298)\t0.13528120342354485\n",
      "  (1, 10661)\t0.15604079163411583\n",
      "  (1, 8234)\t0.10493113958852576\n",
      "  (1, 17194)\t0.19754287223817263\n",
      "  (1, 9137)\t0.21315178964712672\n",
      "  (1, 14049)\t0.2971475606025037\n",
      "  (1, 19999)\t0.17385376710334266\n",
      "  (1, 8261)\t0.060579354529600574\n",
      "  :\t:\n",
      "  (28335, 13761)\t0.31998057575682876\n",
      "  (28335, 2035)\t0.2564392981387361\n",
      "  (28335, 17583)\t0.2003298512268467\n",
      "  (28335, 3944)\t0.21301679305568283\n",
      "  (28335, 18294)\t0.3004160720017759\n",
      "  (28335, 11728)\t0.20648948288296823\n",
      "  (28335, 9381)\t0.11511119300530137\n",
      "  (28335, 21930)\t0.10771242152138431\n",
      "  (28335, 20215)\t0.08522692892035708\n",
      "  (28335, 1284)\t0.1271972482764846\n",
      "  (28335, 9139)\t0.09792180452274159\n",
      "  (28336, 7528)\t0.4477979934970239\n",
      "  (28336, 3024)\t0.41206764075192465\n",
      "  (28336, 12705)\t0.3087348417945812\n",
      "  (28336, 7953)\t0.24481017099905622\n",
      "  (28336, 21543)\t0.2469402308434044\n",
      "  (28336, 8901)\t0.2720780558492315\n",
      "  (28336, 15958)\t0.30587754605910056\n",
      "  (28336, 17211)\t0.2598719803086176\n",
      "  (28336, 19981)\t0.22795378381695058\n",
      "  (28336, 6705)\t0.20171098449314315\n",
      "  (28336, 2443)\t0.21112939720340168\n",
      "  (28336, 8261)\t0.0994179053528658\n",
      "  (28336, 19961)\t0.07034244411986375\n",
      "  (28336, 18806)\t0.1620792341778589\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('X_train_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_tfidf, f)\n",
    "    \n",
    "with open('X_train_tfidf.pkl', 'rb') as f:\n",
    "    X_train_tfidf_loaded = pickle.load(f)\n",
    "\n",
    "print(X_train_tfidf_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a690e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('xgb_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_classifier, f)\n",
    "\n",
    "with open('xgb_classifier.pkl', 'rb') as f:\n",
    "    xgb_classifier_loaded = pickle.load(f)\n",
    "\n",
    "print(xgb_classifier_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cd7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer_model.pkl')\n",
    "\n",
    "tfidf_vectorizer_loaded = joblib.load('tfidf_vectorizer_model.pkl')\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer_loaded.transform(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "restaurant",
   "language": "python",
   "name": "restaurant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
